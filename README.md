# HD-AI_CHALLENGE_FINAL

## 🏆 Result
- **Leader Board Score(1st)

<br>

<br>

본선진출시
<img width="100%" src="https://github.com/jjuhyeok/HD-AI_CHALLENGE/assets/49608953/79e812c3-1fab-44a1-be18-e5ac64883372"/>  
<br>

<br>

주최 : HD한국조선해양 AI Center  
  
주관 : DACON   
  
규모 : 총 1320여명 참가  

<br>
==========================================================
  
  

  

✏️
**대회 느낀점**  
이번 대회를 진행하며 내가 제일 자신있던 부분에 대해 다시 한번 생각할 수 있었던 대회였습니다.  
평소 데이터속에서 인사이트를 찾고 그 인사이트를 이용할 수 있는 방법들을 만드는 것을 좋아했었고  
그만큼 EDA는 좋아하며 자신이있었습니다.  
하지만 이번 대회는 그 자신감에서 오는 부주의함을 깨달을 수 있었습니다.  
대회를 진행하며 모델링을 했을 때 "유가" 정보를 제외하고 modeling을 하면 점수가 많이 떨어졌습니다.  
저는 이 현상을 보며 "아! 유가 정보는 간접적으로 시간에 대한 정보를 주기 때문에, 이번 모델링의 핵심은 먼저 시간에 대한 정보를 많이 표현을 해야겠다" 라며  
대회에서 제공되지 않는 달러 외부데이터와 같은 데이터도 가져와서 사용하고 다양한 피처 엔지니어링 기법들을 통해  
학습 데이터에 "시간"에 대한 표현을 많이 해주려 노력을 했었습니다.  
그 결과 리더보드 상으로 보았을 때 모델링 정확도가 최상위권에 위치할 수 있었습니다.  
아마 피처 엔지니어링을 통해 모델이 Feature Extraction을 잘 할수 있도록 했던 것 같습니다.  
하지만 대회가 반 이상 지났을 때, 데이터의 이상이 있다는 점이 확인되었고    
대회의 데이터가 변경되며 리더보드도 리셋이 되었습니다.  
문제는 원유에 미래값인 Target값의 정보가 포함이 되어있었기 때문이었습니다.  
이걸 알고 있었던 사람들은 로직과 같은 방법을 이용해 최고점을 찍고 있었습니다.    
물론 데이터 오류였지만 스스로 데이터에는 미래의 값(Data Leakage)이 포함이 안되어있을거라고 가정을 하며 진행했던것이  
원유 데이터에 에러가 있음을 파악하지 못했다는 것을 알았습니다.  
이번 경험으로 당연히 아니겠지라고 넘기는 고정관념에서 벗어나 더 정확한 분석을 해야겠다고 깨달았습니다.  
<br>
리더보드 초기화 후 새로운 데이터로 다시 모델링을 시작했는데   
이 깨달음으로 다시 한번 천천히 EDA를 해보았습니다.   
EDA결과 기상정보 데이터들에 대해 Target값의 미래 정보를 포함하는 것으로 보였습니다.  
주최측에서는 유가 지수와는 다르게 공신력 있는 기관의 예보 정보를 활용한 변수라는 점과 현실에서도 예보 데이터를 활용하고 있다는 점에서 해당 변수에 대해서는 현행과 같이 본 대회의 규칙을 벗어나지 않는 선에서 활용하여 진행해도 된다고 하셨습니다.  
그래서 저는 Target값 예측에 대한 Custom 알고리즘 로직을 만들었습니다.  

### Logic  
<br>
<br>

Test 샘플의 날짜보다 미래의 Train 데이터에 동일한 피처 조합을 가진 샘플이 없는 경우:  
Test 샘플의 CI_HOUR 값은 그대로 반환.  

Test 샘플의 날짜보다 미래의 Train 데이터에 동일한 피처 조합을 가진 샘플이 있는 경우:  
가장 가까운 미래의 Train 샘플을 찾기. 해당 Train 샘플의 CI_HOUR 값과, Test 샘플과 Train 샘플 사이의 시간 차이를 합산하여 반환.  

예시:
2021년 6월 9일: 피처의 값은 각 a, b, c, d이며, CI_HOUR(Target)는 450.  
2023년 2월 3일에 동일한 피처 조합 (a, b, c, d)를 가진 Train 샘플이 있으며, 해당 샘플의 CI_HOUR 값은 0.  
따라서 후처리된 값은 시간 차이인 12456.9시간 + 0 = 12456.9시간.  

2022년 11월 11일: 피처의 값은 각 a, b, c, d이며, CI_HOUR(Target)는 0.1.  
해당 날짜 이후에 동일한 피처 조합을 가진 Train 데이터가 없음.  
따라서 후처리된 값은 0.1.  

2022년 11월 18일: 피처의 값은 각 a, b, c, d이며, CI_HOUR(Target)는 1000.  
2023년 2월 3일에 동일한 피처 조합 (a, b, c, d)를 가진 Train 샘플이 있으며, 해당 샘플의 CI_HOUR 값은 0.  
따라서 후처리된 값은 시간 차이인 1776시간 + 0 = 1776시간.  

2023년 2월 3일: 피처의 값은 각 a, b, c, d이며, CI_HOUR(Target)는 0.  
해당 날짜 이후에 동일한 피처 조합을 가진 Train 데이터가 없음.  
따라서 후처리된 값은 0.  


이 방법을 사용해 안정적으로 본선에 진출할 수 있는 순위권에 안착할 수 있었고,  
최종 본선 진출 명단에 들게 되었습니다.  

다시 한번 이번 대회를 통해 평소 간과하던 저의 모습을 되돌아 볼 수 있었습니다.  



<br>

<br>
===========================================================================


## Data Info
<br>
  
* train.csv  
Rows : 391,939개  
SAMPLE_ID : 학습 샘플의 고유 ID  
[수정] 유가 정보 Feature Drop ['DUBAI', 'BRENT', 'WTI', 'BDI_ADJ'] (이전 버전 데이터 사용 시 실격)  
Feature 정보는 [링크]에서 참조  
CI_HOUR : 대기시간  


* test.csv  
Rows : 220,491개  
[수정] 유가 정보 Feature Drop ['DUBAI', 'BRENT', 'WTI', 'BDI_ADJ'] (이전 버전 데이터 사용 시 실격)  
SAMPLE_ID : 추론 샘플의 고유 ID  


* sample_submission.csv  
Rows : 220,491개  
SAMPLE_ID : 추론 샘플의 고유 ID  
CI_HOUR : 예측한 대기시간  

---

## Process

**1. EDA**   
  * 나라별, 항구별, 배의 타입별 등등의 특성 확인  
  * 각 배의 카테고리컬한 피처들의 조합의 통계값들 확인  
  * 기상정보에 대한 Target값 로직 파악  
  
**2. Feature Engineering**   
  * 시간 feature들은 inherently cyclical 하다는 특징을 활용하기 위해 sin/cos 변환  
  * 특정 피처들의 target 값의 평균으로 파생 변수 생성  
  * 클러스터링  


**3. Modeling**

  * Optuna를 활용하여 하이퍼파라미터 튜닝  

**3. Validation**
  * 일반적인 K-fold  
  * Year 따른 Stratify K-fold  
  * ARI_CO(나라별)에 따른 Stratify K-fold  
  * ARI_PO(항구별)에 따른 Stratify K-fold (public과 제일 Score 유사 but ARI_PO 샘플이 적은 항구들이 존재)  


  
